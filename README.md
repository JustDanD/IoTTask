# Брокер сообщений Kafka как трасса данных

## Задание 1

- В данном задании мной была реализована передача данных из одной MongoDB базы в другую при помощи Kafka и Kafka Connect.
- Решение содержит в себе docker-compose.yml, описывающий используемые докер контейнеры, скрипты для инициализации баз данных в директориях sourceScripts и targetScripts, директорию kafka-connect с Dockerfileом внутри, через который устанавливается коннектор MongoDb, , и конфигами коннекторов, а так же скрипты для запуска и остановки решения.
- docker-compose содержит в себе следующие контейнеры:

  - mongoSource - контейнер для базы-источника

    - Используемый внешний порт - 27017

  - mongoTarget - контейнер для целевой базы

    - Используемый внешний порт - 27017

  - mongo-express-source - вьюявер для базы-источник

    - Используемый внешний порт - 8081

  - mongo-express-target - вьюявер для целевой базы

    - Используемый внешний порт - 8082

  - zookeeper
    - Используемый внешний порт - 22181
    - Используемый внутренний порт - 2181
  - kafka

    - hostname - kafka
    - внешний порт - 29092
    - внутренний порт - 9092

  - schema-registry
    - hostname - schema-registry
    - внешний порт - 8085
    - внутренний порт - 8082
  - kafka-connect
    - hostname - kafka-connect
    - внешний порт - 8083
    - внутренний порт - 8083
  - akhq - GUI для управления kafka вместо kafka ui. Мне показался удобнее.
    - Адрес для подключения - localhost:8080

- Для запуска решения необходимо сделать исполняемым файл ./run.sh (chmod +x run.sh) и запустить его с правами администратора (sudo ./run.sh). Это необходимо для установки корректных прав доступа для файла ключ mongoDB, нужного для запуска replicaSet. И подождать минуту.
- Для остановки решения необходимо сделать исполняемым файл ./stop.sh (chmod +x stop.sh) и запустить его (sudo ./stop.sh)
- Принцип решения довольно прост. Мы устанавливаем коннектор MongoDB для kafka-connect, настраиваем конфиги для обоих коннектор в соответствии с документацией и запускаем решение. Оно работает.

## Задание 2

- С точки зрения реализации данная задача отличается несильно. Остаются все те же контейнеры из прошлого списка, но к ним добавляется worker. К сожалению, полноценно разобраться со Schema Registry, спустя 5 часов попыток, разобраться не получилось, поэтому было принято решение написать кастомный воркер.
- Первая половина решения остаётся без изменений. Kafka-connect получается данные из MongoDB-Source и кладёт их в топик move. На этот же топик подписан воркер. Когда сообщение попадает в топик, его вычитывает воркер, после чего проверяет и преобразовывает типы. Далее я достаточно костыльно реализовал разрешение ситуации, когда документ с таким id уже существует в целевой базе. Для этого воркер получается из целевой базы все id и генерирует строку, которой нет в полученном массиве, после чего использует её в качестве нового id.
- Для запуска решения необходимо сделать исполняемым файл ./run.sh (chmod +x run.sh) и запустить его с правами администратора (sudo ./run.sh). Это необходимо для установки корректных прав доступа для файла ключ mongoDB, нужного для запуска replicaSet. И подождать минуту.
- Для остановки решения необходимо сделать исполняемым файл ./stop.sh (chmod +x stop.sh) и запустить его (sudo ./stop.sh)

## Задание 3

- Это задание полностью делается по документации ClickHouse. В docker-compose поднимаются контейнеры kafka, schema registry, akhq из прошлых заданий и clickhouseSrv. Далее в clickHouse создаются таблицы: таблица для данных из кафка, итоговая таблица metrics и view для преобразования информации и таблицы для кафки в metrics.
- Исходные данные для теста взяты из репозитория, который использовался для проработки вопроса, и имеют следующий вид:

```json
{
	"payload": {
		"before": "null",
		"after": {
			"id": "cf59290c-4627-4374-b2e4-93fff26c448b",
			"area": "CA",
			"event_time": "2022-01-01 00:00:00",
			"type": "LOGIN_ERROR",
			"user_id": "123",
			"details_json": "{\"auth_method\":\"openid-connect\",\"grant_type\":\"password\",\"client_auth_method\":\"client-secret\",\"username\":\"kuku\"}"
		}
	}
}
```

- Аналогичные таблицы созданы в clickHouse. Для просмотра результата можно вызвать docker exec -it clickhouse-server clickhouse-client --query="SELECT \* FROM metrics;".
- clickhouse-server живёт на порту 8131.
- После попадания данных в топик, они автоматически вычитываются и попадают в соответствующую таблицу ClickHouse.
- Для запуска решения необходимо сделать исполняемым файл ./run.sh (chmod +x run.sh) и запустить его с правами администратора (sudo ./run.sh).
- Для остановки решения необходимо сделать исполняемым файл ./stop.sh (chmod +x stop.sh) и запустить его (sudo ./stop.sh)
